## Step 1: Exploring and preparing the data
# read in data and examine structure
letters <- read.csv("letterdata.csv")
str(letters)
install.packages("C50")
setwd("~/Desktop/TO 414")
library(c50)
str(iris)
mod1 <- c5.0(Species ~ ., data = iris)
plot(mod1)
library(c50)
mod1 <- c5.0(Species ~ ., data = iris)
plot(mod1)
install.packages("c50")
install.packages("C50")
library(C50)
mod1 <- c5.0(Species ~ ., data = iris)
plot(mod1)
library(C50)
mod1 <- C5.0(Species ~ ., data = iris)
plot(mod1)
install.packages(c("irr", "randomForest", "ROCR"))
setwd("~/Desktop/TO 414")
## Visualizing Performance Tradeoffs ----
sms_results <- read.csv("sms_results.csv")
head(sms_results)
head(subset(sms_results, actual_type != predict_type))
library(ROCR)
install.packages("ROCR")
install.packages("ROCR")
pred <- prediction(predictions = sms_results$prob_spam,
labels = sms_results$actual_type)
pred <- prediction(predictions = sms_results$prob_spam,
labels = sms_results$actual_type)
## Visualizing Performance Tradeoffs ----
sms_results <- read.csv("sms_results.csv")
head(sms_results)
head(subset(sms_results, actual_type != predict_type))
library(ROCR)
pred <- prediction(predictions = sms_results$prob_spam,
labels = sms_results$actual_type)
# ROC curves
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC curve for SMS spam filter", col = "blue", lwd = 2)
# add a reference line to the graph
abline(a = 0, b = 1, lwd = 2, lty = 2)
# calculate AUC
perf.auc <- performance(pred, measure = "auc")
str(perf.auc)
as.numeric(perf.auc@y.values)
# 10-fold CV
folds <- createFolds(credit$default, k = 10)
str(folds)
credit01_train <- credit[folds$Fold01, ]
credit01_test <- credit[-folds$Fold01, ]
## Automating 10-fold CV for a C5.0 Decision Tree using lapply() ----
library(caret)
library(C50)
library(irr)
set.seed(123)
# load the credit dataset
credit <- read.csv("credit.csv")
library(caret)
## Creating a simple tuned model ----
# automated parameter tuning of C5.0 decision tree
set.seed(300)
m <- train(default ~ ., data = credit, method = "C5.0")
# summary of tuning results
m
# apply the best C5.0 candidate model to make predictions
p <- predict(m, credit)
table(p, credit$default)
m <- train(default ~ ., data = credit, method = "C5.0")
## Random Forests ----
# random forest with default settings
library(randomForest)
set.seed(300)
rf <- randomForest(default ~ ., data = credit)
rf
library(caret)
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10)
# auto-tune a random forest
grid_rf <- expand.grid(.mtry = c(2, 4, 8, 16))
set.seed(300)
m_rf <- train(default ~ ., data = credit, method = "rf",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_rf)
m_rf
