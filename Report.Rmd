---
title: "Report"
author: "Arsyad, Athilah, Jen Lyn, Rongqing, Yunjia"
date: "3/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(kernlab)
```

CONTENTS:
1. [Introduction]<br />
2. [Data Exploration]<br />
3. [Prediction Model]:<br />
    + [Logistic Regression Model]<br />
    + [KNN Model]<br />
    + [SVM Model]<br />
    + [ANN Model]<br />
    + [Decision Tree]<br /> 
    + [Boosting]<br />
    + [Bagging]<br />
    + [Stacked Model]<br />
4. [Conclusion]<br />


## Introduction

Pet adoption problem has recently drawn people's attention, as more people want to adopt a pet during the global pandemic. It is important for animal shelters and related business to predict how soon pets can find their owner. We want to build data models using R to help with the predictions. The dataset to moltivate this study is from https://www.kaggle.com/c/petfinder-adoption-prediction/data, which contain data for cats and dogs. Specifically, we want to predict how soon a pet can be adopted, based on various features including type, gender, health, etc. We also want to explore the dataset to find if there is anything interesting or surprising.

## Data Exploration

### Interesting Insights
#### What are the most popular names for pets?
```{r, echo= TRUE}
pet <- read.csv("train.csv")
library(dplyr)
catbyname <- pet %>% filter(Type == 2 & Name != "" & Name != "No Name")%>% group_by(Name) %>% summarize(total = n(), avg_speed = mean(AdoptionSpeed)) %>% arrange(desc(total)) %>% slice(1:10)
catbyname
```
10 Most Popular Cats' Name: Kittens, Kitty, Baby, Mimi, Kitten, Ginger, Tiger, Kiki, Snowy, Blackie


```{r, echo= TRUE}
dogbyname <- pet %>% filter(Type == 1 & Name != "" & Name != "No Name") %>% group_by(Name) %>% summarize(total = n(), avg_speed = mean(AdoptionSpeed)) %>% arrange(desc(total)) %>% slice(1:10)
dogbyname
```
10 Most Popular Dogs' Name: Lucky, Puppy, Brownie, Max, Baby, Blackie, Coco, Bobby, Puppies, Angel

#### What are the names for pets that got adopted faster than others?

```{r, echo= TRUE}
catbyspeed <- catbyname %>% arrange(avg_speed)
catbyspeed
```

Among the top 5 popular names for cats are Blackie, Mimi, Tiger, Kitty and Kitten. Cats with such names were adopted faster than other cats with different names.

```{r, echo= TRUE}
dogbyspeed <- dogbyname %>% arrange(avg_speed)
dogbyspeed
```

Among the top 5 popular names for dogs are Lucky, puppies, Blackie, Bobby and Maxare. Dogs with those names were adopted faster than others.

### Data Cleaning
When we considered the data for prediction models, we made slight changes to the data to better fit our models. We did not require the information of the pets' second breed. Instead, we changed this information to whether the pet is a mixed breed or if it's a pure breed. We also change the ranges of the response variable, pets' adoption speed. We were given adoption speed of the following:

0 - Pet was adopted on the same day as it was listed. 
1 - Pet was adopted between 1 and 7 days (1st week) after being listed. 
2 - Pet was adopted between 8 and 30 days (1st month) after being listed. 
3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. 
4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).

We infer that it is more beneficial for animal shelters and animal-related businesses to have information whether pets were adopted within a month or they will be adopted more than a month or never get adopted. This is because we believe that accounting are mostly done monthly. Hence, we change the response variable, pets' adoption speed, into just 2 groups: 1) Adopted within a month (31 days) or 2) Adopted after a month (31 days) or not adopted.
```{r, echo= TRUE}
pet <- read.csv("train.csv")

# Remove unrelated data
pet$Name <- NULL
pet$State <- NULL
pet$RescuerID <- NULL
pet$Description <- NULL
pet$PetID <- NULL

pet$Type <- as.factor(pet$Type)
pet$Breed1 <- as.factor(pet$Breed1)
pet$Gender <- as.factor(pet$Gender)
pet$MaturitySize <- as.factor(pet$MaturitySize)
pet$FurLength <- as.factor(pet$FurLength)
pet$Vaccinated <- as.factor(pet$Vaccinated)
pet$Dewormed <- as.factor(pet$Dewormed)
pet$Sterilized <- as.factor(pet$Sterilized)
pet$Health <- as.factor(pet$Health)

# Classify "mixed breed" pets
pet$mixedbreed <- ifelse(pet$Breed2 == 0, 0,1)
pet$Breed2 <- NULL
pet$mixedbreed <- as.factor(pet$mixedbreed)

# Reclassify the AdoptionSpeed into binary format
pet$AdoptionSpeed <- ifelse(pet$AdoptionSpeed == 0 | pet$AdoptionSpeed == 1 | pet$AdoptionSpeed == 2, 0,1 )

str(pet)
```

### Normalizing Data
```{r, echo = TRUE}

# Prepare normalized dataset for potential use
pet_random <- pet[sample(nrow(pet)), ]

normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

pet$AdoptionSpeed <- as.factor(pet$AdoptionSpeed)
pet$AdoptSpeed <- pet$AdoptionSpeed
pet$AdoptionSpeed <- NULL

library(dummies)
pet_dummy <- dummy.data.frame(data = pet[,-ncol(pet)],)

pet_norm <- as.data.frame(lapply(pet_dummy, normalize))
pet_norm$AdoptionSpeed <- pet$AdoptSpeed
```

### Preparing Dataset
```{r, echo= TRUE}
# Split the dataset for 80% training and 20% testing
set.seed(3)
trainid <- sample(1:nrow(pet_norm), .8*nrow(pet_norm))
train <- pet_norm[trainid,]
test <- pet_norm[-trainid,]
train_labels <- train$AdoptionSpeed
test_labels <- test$AdoptionSpeed
```

## Prediction Model
### Logistic Regression Model 
```{r}
glmodel <- glm(AdoptionSpeed ~. , data = train ,family = "binomial")
# summary(glmodel)

glm_result1<-predict(glmodel, train)
glm_tr <- ifelse(glm_result1>mean(glm_result1),1,0)

glm_result<-predict(glmodel, test)
glm_pred <- ifelse(glm_result>mean(glm_result),1,0)
library(caret)
confusionMatrix(as.factor(glm_pred),test$AdoptionSpeed)
glm_acc <- mean(glm_pred ==test_labels)
glm_acc
```

From the logistic regression model, we can see that *type*, *age*, *breed*, *gender*, *color*,*size*, *FurLength*, *Sterilized*, *Health*, *Vaccinated* and *quantity* are some important variables that influence the speed of adoption. Interestingly, we can see that cats, on average, are adopted more quickly than dogs. It is much harder for male pets to be adopted than female pets, or a group of mixed pets. Moreover, medium-size pets tend to get adopted better than other pets of different sizes. And as we thought, healthy is a key for the adoption speed. From the logistic model, sterilized and vaccinated pets in good condition are highly likely to be adopted.

### KNN Model
```{r}
library(class)
knn_pred <- knn(train = train, test = test,
                      cl = train_labels, k=sqrt(ncol(train)))
knn_tr <- knn(train = train, test = train,
                      cl = train_labels, k=sqrt(ncol(train)))

```
```{r}
library(gmodels)
CrossTable(x = test_labels, y = knn_pred, 
           prop.chisq=FALSE)
```

```{r}
knn_acc<- mean(knn_pred == test_labels)
knn_acc
```
In building the model, we think the best *k* is the sqrt of the number of variables. In fact, this model produce a high accuracy rate of `r knn_acc` for the test data. Further model exploration might be necessary to improve this prediction. (see [Stacked Model])

### SVM Model
```{r}
library(kernlab)
pet_classifier_rbf <- ksvm(AdoptionSpeed ~ Type1 + Type2 + MaturitySize1 + MaturitySize2 + MaturitySize3 + MaturitySize4 + FurLength1 + FurLength2 + FurLength3 + Vaccinated1 + Vaccinated2 + Vaccinated3 + Dewormed1 + Dewormed2 + Dewormed3 + Sterilized1 + Sterilized2 + Sterilized3 + Health1 + Health2 + Health3 + Quantity + PhotoAmt + mixedbreed0 + mixedbreed1, data = train, kernel = "rbfdot")

svm_tr <-predict(pet_classifier_rbf, train) ##
svm_pred <- predict(pet_classifier_rbf, test)

library(gmodels)
CrossTable(x = test_labels, y = svm_pred, 
           prop.chisq=FALSE)

svm_acc<- mean(svm_pred == test$AdoptionSpeed)
svm_acc

```
We checked all the affecting variables and substituted the breed factor with mixed breed factor. After building two SVM Models (one with kernel of vanilladot, another with rbfdot), we discovered that the rbfdot possessed higher accuracy. Hence we chose rbfdot SVM model for our prediction which gives an accuracy rate of `r svm_acc`.

### ANN Model
```{r}
# The setup 
anndata <- read.csv("train.csv")
anndata$Name <- NULL
anndata$State <- NULL
anndata$RescuerID <- NULL
anndata$Description <- NULL
anndata$PetID <- NULL

anndata$Color1 <- as.factor(anndata$Color1)
anndata$Color2 <- as.factor(anndata$Color2)
anndata$Color3 <- as.factor(anndata$Color3)
anndata$Type <- as.factor(anndata$Type)
anndata$Breed1 <- as.factor(anndata$Breed1)
anndata$Gender <- as.factor(anndata$Gender)
anndata$MaturitySize <- as.factor(anndata$MaturitySize)
anndata$FurLength <- as.factor(anndata$FurLength)
anndata$Vaccinated <- as.factor(anndata$Vaccinated)
anndata$Dewormed <- as.factor(anndata$Dewormed)
anndata$Sterilized <- as.factor(anndata$Sterilized)
anndata$Health <- as.factor(anndata$Health)
anndata$mixedbreed <- ifelse(anndata$Breed2 == 0, 0,1)
anndata$Breed2 <- NULL
anndata$mixedbreed <- as.factor(anndata$mixedbreed)
anndata$AdoptionSpeed <- ifelse(anndata$AdoptionSpeed == 0 | anndata$AdoptionSpeed == 1 | anndata$AdoptionSpeed == 2, 0,1 )

response <- anndata$AdoptionSpeed
anndata$AdoptionSpeed <- NULL
anndata$AdoptionSpeed <- response
```

```{r}
# Normalize data
anndata_random <- anndata[sample(nrow(anndata)), ]

normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

anndata_n1 <- as.data.frame(lapply(anndata_random[2], normalize))
anndata_n2 <- as.data.frame(lapply(anndata_random[14:17], normalize))

anndata_n <- data.frame(c(anndata_random[1], anndata_n1, anndata_random[3:13], anndata_n2, anndata_random[18:19]))
```
```{r}
anndata_mm<- as.data.frame(model.matrix(~ . -1, anndata_n))
```

```{r}
set.seed(3)
anntrainid <- sample(1:nrow(anndata_mm), .8*nrow(anndata_mm))
anntrain <- anndata_mm[anntrainid,]
anntest <- anndata_mm[-anntrainid,]
anntrain_labels <- anntrain$AdoptionSpeed
anntest_labels <- anntest$AdoptionSpeed
```

```{r}
library(neuralnet)
m1 <- neuralnet(formula = AdoptionSpeed ~ . , data = anntrain)
```

```{r}
library(class)
library(gmodels)
library(neuralnet)
library(caret)

ann_result1 <- compute(m1,anntrain)
predicted1 <- ann_result1$net.result
summary(predicted1)
ann_tr <- ifelse(predicted1 > mean(predicted1) , 1, 0) # for stacked model

ann_result <- compute(m1,anntest)
predicted <- ann_result$net.result
summary(predicted)
ann_pred <- ifelse(predicted > mean(predicted) , 1, 0)


pet_cM_ann <- confusionMatrix(as.factor(ann_pred), as.factor(anntest_labels))
pet_cM_ann

ann_acc <- mean(ann_pred == anntest_labels)
ann_acc
```
From the ANN model, we can see that the accuracy for predicting the adoption speed of the pets is `r ann_acc`. This is not a very high accuracy level, however, it is compatible with other models. We can improve this model by increasing the hidden neurons of the model. However, doing so will affect the time taken for the model to run and will only increase the accuracy by a little.

### Decision Tree
```{r}
# Train a model
library(C50)
pet_model <- C5.0(train[-ncol(train)], train$AdoptionSpeed)

```

```{r}
# Evaluating model
tree_tr <- predict(pet_model, train) #for stacked model

tree_pred <- predict(pet_model, test)


library(gmodels)
CrossTable(test$AdoptionSpeed, tree_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

tree_acc<-mean(tree_pred == test$AdoptionSpeed)
tree_acc
```

### Boosting
```{r}
## Boosting the accuracy of decision trees
# boosted decision tree with 10 trials
pet_boost10 <- C5.0(train[-ncol(train)], train_labels,
                       trials = 10)


boost10_tr <- predict(pet_boost10, train) #for stacked model

boost10_pred <- predict(pet_boost10, test)
CrossTable(test$AdoptionSpeed, boost10_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))
boost10_acc<- mean(boost10_pred == test_labels)
boost10_acc
```

### Bagging
```{r}
# Using the ipred bagged decision trees to improve the logistic model
library(ipred)
set.seed(3)
mybag <- bagging(AdoptionSpeed ~ ., data = train, nbagg = 25)


bag_tr <- predict(mybag, train) # for stacked model

bag_pred <- predict(mybag, test)
table(bag_pred, test$AdoptionSpeed)
bag_acc <- mean(bag_pred ==test_labels)
bag_acc

library(caret)
ctrl <- trainControl(method = "cv", number = 10)
train(AdoptionSpeed ~ ., data = test, method = "treebag",
      trControl = ctrl)
```
The model's accuracy is `r bag_acc`, which seems to have fit the training data well. And the kappa statistic of 0.21 for this model suggests that the bagged tree model performs on par with our C5.0 decision tree.

### Stacked Model

We obtained different accuracy rates from the previous seven models:
```{r}
Model =c("Logistic Regression", "KNN", "SVM", "ANN",
                                 "Tree", "Boosting", "Bagging")
Accuracy_Rate = c(glm_acc, knn_acc, svm_acc, ann_acc,
                                          tree_acc, boost10_acc, bag_acc)
dotchart(Accuracy_Rate, labels = Model, main = "Accuracy of the models", xlab = "Accuracy")
```
Only KNN produces a high accuracy rate while others remain at about 60%. So, we believe that stacking the models using trees will produce a better accuracy rate.

```{r}
#Preparing Dataset

PredictedTr <- data.frame(glm_tr, knn_tr, svm_tr, ann_tr,
                        tree_tr, boost10_tr, bag_tr)

Predicted <- data.frame(glm_pred, knn_pred, svm_pred, ann_pred,
                        tree_pred, boost10_pred, bag_pred)
library(C50)
stacked<- C5.0(PredictedTr[-ncol(PredictedTr)],train$AdoptionSpeed, trials = 5)

names(Predicted)<- names(PredictedTr)
stacked_pred<-predict(stacked, Predicted)

stacked_acc<- mean(stacked_pred == test_labels)
stacked_acc
plot(stacked)
```
As expected, the accuracy rate of this stacked model is `r stacked_acc` which is an improvement from the highest accuracy rate, KNN's (`r knn_acc`).

## Conclusion

We have predicted whether a pet gets adopted within a month (31 days) or not using 8 models. The accuracy rate are as followed:
```{r}
Accuracy<-data.frame( "Model" =c("Logistic Regression", "KNN", "SVM", "ANN",
                                 "Tree", "Boosting", "Bagging", "Stacked Model" ),
                      "Accuracy Rate" = c(glm_acc, knn_acc, svm_acc, ann_acc,
                                          tree_acc, boost10_acc, bag_acc, stacked_acc))

Accuracy
```

We can use the stacked model to predict the adoption speed with the best accuracy. With around 96% accuracy, we are sure that this model can help animal shelters around the world in getting stray animals get adopted with in their best condition. Predicting the pet’s adoption speed will benefit companies in terms of resources optimization. This includes pets’ medical appointments with veterinarians. If they know how long will a pet be adopted, they can budget the food distribution, manage spaces for the pets and if they should place more pets for adoption.

This report also offers valueable insights on how related business can manage the inventory better. There are factors including *Sterilized*, *Health*, *Vaccinated* which can have impacts on the adoption speed. These are adoption centers owners can make a difference in helping the animal, helping future owners, and eventually helping the adoptiong progress. It is also suggested for shelters to give names to the pets, even generalized names like kitten/puppy seems to work well, or popular name for male dog like "Max". 

We hope our efforts can help the global efforts to encourge more people to stay at home to enjoy time with their pets! 

